{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TITANIC DATASET ANALYSIS AND PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from six.moves import urllib\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"titanic.csv\")\n",
    "dataset.shape\n",
    "dataset.dropna(axis=0, inplace=True, subset=[\"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Pclass\",\"Embarked\",\"Fare\"])\n",
    "#print(dataset)\n",
    "y = dataset[\"Survived\"]\n",
    "X = dataset.iloc[:, 4:8]\n",
    "X=np.column_stack((X, dataset[\"Pclass\"]))\n",
    "X= np.column_stack((X,dataset[\"Embarked\"]))\n",
    "X=np.column_stack((X, dataset[\"Fare\"]))\n",
    "X = pd.DataFrame(data=dataset, columns=[\"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Pclass\",\"Embarked\",\"Fare\"])\n",
    "#X.dropna(axis=0, inplace=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "430    1\n",
       "14     0\n",
       "770    0\n",
       "750    1\n",
       "287    0\n",
       "      ..\n",
       "78     1\n",
       "800    0\n",
       "623    0\n",
       "16     0\n",
       "120    0\n",
       "Name: Survived, Length: 143, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.20, random_state=32)\n",
    "X_train.shape\n",
    "X_test.shape\n",
    "y_train\n",
    "y_test\n",
    "\n",
    "#X_train.dropna(subset=[\"Pclass\"])\n",
    "#X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##DATA VISUALIZATION BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Sex', 'Age', 'SibSp', 'Parch', 'Pclass', 'Embarked', 'Fare'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>712.000000</td>\n",
       "      <td>712.000000</td>\n",
       "      <td>712.000000</td>\n",
       "      <td>712.000000</td>\n",
       "      <td>712.000000</td>\n",
       "      <td>712.000000</td>\n",
       "      <td>712.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>448.589888</td>\n",
       "      <td>0.404494</td>\n",
       "      <td>2.240169</td>\n",
       "      <td>29.642093</td>\n",
       "      <td>0.514045</td>\n",
       "      <td>0.432584</td>\n",
       "      <td>34.567251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>258.683191</td>\n",
       "      <td>0.491139</td>\n",
       "      <td>0.836854</td>\n",
       "      <td>14.492933</td>\n",
       "      <td>0.930692</td>\n",
       "      <td>0.854181</td>\n",
       "      <td>52.938648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>222.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>445.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.645850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>677.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>33.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   712.000000  712.000000  712.000000  712.000000  712.000000   \n",
       "mean    448.589888    0.404494    2.240169   29.642093    0.514045   \n",
       "std     258.683191    0.491139    0.836854   14.492933    0.930692   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     222.750000    0.000000    1.000000   20.000000    0.000000   \n",
       "50%     445.000000    0.000000    2.000000   28.000000    0.000000   \n",
       "75%     677.250000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    5.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  712.000000  712.000000  \n",
       "mean     0.432584   34.567251  \n",
       "std      0.854181   52.938648  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    8.050000  \n",
       "50%      0.000000   15.645850  \n",
       "75%      1.000000   33.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataset.Embarked.value_counts()\n",
    "print(X.columns)\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d1275e8308>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.Age.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d1296efac8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.Sex.value_counts().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d1297603c8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.Embarked.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d1297b9848>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.Pclass.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d129825688>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.groupby('Survived')['Sex'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "##LINEAR REGRESSION WITH TENSORFLOW BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22.   38.   26.   35.   54.    2.   27.   14.    4.   58.   20.   39.\n",
      " 55.   31.   34.   15.   28.    8.   19.   40.   66.   42.   21.   18.\n",
      "  3.    7.   49.   29.   65.   28.5   5.   11.   45.   17.   32.   16.\n",
      " 25.    0.83 30.   33.   23.   24.   46.   59.   71.   37.   47.   14.5\n",
      " 70.5  32.5  12.    9.   36.5  51.   55.5  40.5  44.    1.   61.   56.\n",
      " 50.   36.   45.5  20.5  62.   41.   52.   63.   23.5   0.92 43.   60.\n",
      " 10.   64.   13.   48.    0.75 53.   57.   80.   70.   24.5   6.    0.67\n",
      " 30.5   0.42 34.5  74.  ]\n"
     ]
    }
   ],
   "source": [
    "CAT_COL = [\"Sex\", \"Embarked\", \"Pclass\"]\n",
    "NUM_COL = [\"Age\", \"Fare\",\"Parch\",\"SibSp\"]\n",
    "print(X[\"Age\"].unique())\n",
    "feature_col = []\n",
    "for col in CAT_COL :\n",
    "    vocab = X[col].unique()  #list of all unique values\n",
    "    feature_col.append(tf.feature_column.categorical_column_with_vocabulary_list(col, vocab))\n",
    "    \n",
    "for col in NUM_COL:\n",
    "    feature_col.append(tf.feature_column.numeric_column(col, dtype= tf.float32))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[VocabularyListCategoricalColumn(key='Sex', vocabulary_list=('male', 'female'), dtype=tf.string, default_value=-1, num_oov_buckets=0),\n",
       " VocabularyListCategoricalColumn(key='Embarked', vocabulary_list=('S', 'C', 'Q'), dtype=tf.string, default_value=-1, num_oov_buckets=0),\n",
       " VocabularyListCategoricalColumn(key='Pclass', vocabulary_list=(3, 1, 2), dtype=tf.int64, default_value=-1, num_oov_buckets=0),\n",
       " NumericColumn(key='Age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='Fare', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='Parch', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='SibSp', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_fn(data_df, label_df, num_epochs=10, shuffle=True, batch_size=32):\n",
    "    def input_function():  #inner function, this will be returned\n",
    "        #create tf.data.Dataset object with data and its label\n",
    "        ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df)) \n",
    "        if shuffle:\n",
    "            ds = ds.shuffle(1000) #randomize order of data\n",
    "        ds = ds.batch(batch_size).repeat(num_epochs) #split into batches of 32, repeat process for number of epochs\n",
    "        return ds  #return a batch of dataset\n",
    "    return input_function  #return a function object for use\n",
    "\n",
    "train_input_fn = make_input_fn(X_train, y_train)\n",
    "test_input_fn = make_input_fn(X_test, y_test, num_epochs=1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function make_input_fn.<locals>.input_function at 0x000001D129857708>\n"
     ]
    }
   ],
   "source": [
    "#dict(X_train)\n",
    "print(train_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\91930\\AppData\\Local\\Temp\\tmpybchlca5\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\91930\\\\AppData\\\\Local\\\\Temp\\\\tmpybchlca5', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:From C:\\Users\\91930\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From C:\\Users\\91930\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer linear/linear_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\91930\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:540: Layer.add_variable (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From C:\\Users\\91930\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\ftrl.py:144: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\91930\\AppData\\Local\\Temp\\tmpybchlca5\\model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 0.6931472, step = 0\n",
      "INFO:tensorflow:global_step/sec: 181.594\n",
      "INFO:tensorflow:loss = 0.48673353, step = 100 (0.556 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 180...\n",
      "INFO:tensorflow:Saving checkpoints for 180 into C:\\Users\\91930\\AppData\\Local\\Temp\\tmpybchlca5\\model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 180...\n",
      "INFO:tensorflow:Loss for final step: 0.54776514.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.linear.LinearClassifierV2 at 0x1d1263d7c48>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_est = tf.estimator.LinearClassifier(feature_columns=feature_col)\n",
    "linear_est.train(train_input_fn)\n",
    "#result = linear_est.predict(test_input_fn)\n",
    "#print(result[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer linear/linear_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-07-24T20:24:29Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\91930\\AppData\\Local\\Temp\\tmpybchlca5\\model.ckpt-180\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 1.58309s\n",
      "INFO:tensorflow:Finished evaluation at 2020-07-24-20:24:31\n",
      "INFO:tensorflow:Saving dict for global step 180: accuracy = 0.73426574, accuracy_baseline = 0.6083916, auc = 0.80880535, auc_precision_recall = 0.74924564, average_loss = 0.64285105, global_step = 180, label/mean = 0.3916084, loss = 0.64576876, precision = 0.625, prediction/mean = 0.5462688, recall = 0.8035714\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 180: C:\\Users\\91930\\AppData\\Local\\Temp\\tmpybchlca5\\model.ckpt-180\n"
     ]
    }
   ],
   "source": [
    "test_result = linear_est.evaluate(test_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer linear/linear_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\91930\\AppData\\Local\\Temp\\tmpybchlca5\\model.ckpt-180\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Sex          female\n",
      "Age              38\n",
      "SibSp             1\n",
      "Parch             0\n",
      "Pclass            1\n",
      "Embarked          C\n",
      "Fare        71.2833\n",
      "Name: 1, dtype: object\n",
      "1\n",
      "0.7984678\n"
     ]
    }
   ],
   "source": [
    "result = list(linear_est.predict(test_input_fn))\n",
    "print(X_test.loc[1])\n",
    "print(y_test.loc[1])\n",
    "print(result[1][\"probabilities\"][1])\n",
    "res = []\n",
    "for i in range(len(result)):\n",
    "    if result[i][\"probabilities\"][1]>=0.5:\n",
    "        res.append(1)\n",
    "    else:\n",
    "        res.append(0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(143, 7)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(res))\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[60, 27],\n",
       "       [11, 45]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, res)\n",
    "cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7272727272727273"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "104/143\n",
    "##TEST SET ACCURACY - 73%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "##LINEAR REGRESSION WITH SKLEARN BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "columnTransformer = ColumnTransformer([('encoder', OneHotEncoder(), [0])], remainder='passthrough')\n",
    "X_train = np.array(columnTransformer.fit_transform(X_train), dtype = np.str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['1.0', '0.0', '45.0', '2.0', '26.25'],\n",
       "       ['0.0', '1.0', '21.0', '3.0', '7.7958'],\n",
       "       ['0.0', '1.0', '28.0', '3.0', '7.8958'],\n",
       "       ...,\n",
       "       ['1.0', '0.0', '20.0', '3.0', '9.825'],\n",
       "       ['1.0', '0.0', '36.0', '2.0', '13.0'],\n",
       "       ['1.0', '0.0', '18.0', '1.0', '227.525']], dtype='<U32')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnTransformer = ColumnTransformer([('encoder', OneHotEncoder(), [6])], remainder='passthrough')\n",
    "X_train = np.array(columnTransformer.fit_transform(X_train), dtype = np.str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>male</td>\n",
       "      <td>28.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>S</td>\n",
       "      <td>26.5500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>female</td>\n",
       "      <td>14.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>S</td>\n",
       "      <td>7.8542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>male</td>\n",
       "      <td>24.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>S</td>\n",
       "      <td>9.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>female</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>S</td>\n",
       "      <td>23.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>287</td>\n",
       "      <td>male</td>\n",
       "      <td>22.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>S</td>\n",
       "      <td>7.8958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>male</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>S</td>\n",
       "      <td>29.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>male</td>\n",
       "      <td>34.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>S</td>\n",
       "      <td>13.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>623</td>\n",
       "      <td>male</td>\n",
       "      <td>21.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>S</td>\n",
       "      <td>7.8542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>male</td>\n",
       "      <td>2.00</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Q</td>\n",
       "      <td>29.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>male</td>\n",
       "      <td>21.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>S</td>\n",
       "      <td>73.5000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Sex    Age  SibSp  Parch  Pclass Embarked     Fare\n",
       "430    male  28.00      0      0       1        S  26.5500\n",
       "14   female  14.00      0      0       3        S   7.8542\n",
       "770    male  24.00      0      0       3        S   9.5000\n",
       "750  female   4.00      1      1       2        S  23.0000\n",
       "287    male  22.00      0      0       3        S   7.8958\n",
       "..      ...    ...    ...    ...     ...      ...      ...\n",
       "78     male   0.83      0      2       2        S  29.0000\n",
       "800    male  34.00      0      0       2        S  13.0000\n",
       "623    male  21.00      0      0       3        S   7.8542\n",
       "16     male   2.00      4      1       3        Q  29.1250\n",
       "120    male  21.00      2      0       2        S  73.5000\n",
       "\n",
       "[143 rows x 7 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 6 is out of bounds for axis 0 with size 5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-85-07491b58fd05>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumnTransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcolumnTransformer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mColumnTransformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'encoder'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mremainder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'passthrough'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumnTransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    453\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_transformers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_column_callables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 455\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_remainder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    456\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_fit_transform_one\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\u001b[0m in \u001b[0;36m_validate_remainder\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    306\u001b[0m         \u001b[0mcols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_columns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 308\u001b[1;33m             \u001b[0mcols\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_get_column_indices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    309\u001b[0m         \u001b[0mremaining_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[0mremaining_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mremaining_idx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\u001b[0m in \u001b[0;36m_get_column_indices\u001b[1;34m(X, key)\u001b[0m\n\u001b[0;32m    659\u001b[0m             or hasattr(key, 'dtype') and np.issubdtype(key.dtype, np.bool_)):\n\u001b[0;32m    660\u001b[0m         \u001b[1;31m# Convert key into positive indexes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 661\u001b[1;33m         \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_columns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    662\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    663\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0m_check_key_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 6 is out of bounds for axis 0 with size 5"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "columnTransformer = ColumnTransformer([('encoder', OneHotEncoder(), [0])], remainder='passthrough')\n",
    "X_test = np.array(columnTransformer.fit_transform(X_test), dtype = np.str)\n",
    "columnTransformer = ColumnTransformer([('encoder', OneHotEncoder(), [6])], remainder='passthrough')\n",
    "X_test = np.array(columnTransformer.fit_transform(X_test), dtype = np.str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(np.float32)\n",
    "y_train = y_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.    ,  0.    ,  1.    , ...,  0.    ,  3.    ,  9.5   ],\n",
       "       [ 0.    ,  0.    ,  1.    , ...,  0.    ,  3.    ,  7.925 ],\n",
       "       [ 0.    ,  0.    ,  1.    , ...,  1.    ,  2.    , 26.25  ],\n",
       "       ...,\n",
       "       [ 1.    ,  0.    ,  0.    , ...,  0.    ,  3.    , 14.4583],\n",
       "       [ 1.    ,  0.    ,  0.    , ...,  0.    ,  2.    , 12.    ],\n",
       "       [ 0.    ,  0.    ,  1.    , ...,  0.    ,  1.    , 26.2875]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.489538  ,  0.71592927,  0.1374774 ,  0.89562285,  0.15016907,\n",
       "        0.2989297 ,  0.09153998,  0.9801729 ,  0.6052326 ,  0.13699013,\n",
       "        0.8581869 ,  0.17106837,  0.75279886,  0.22781897,  0.31195283,\n",
       "        0.28853577,  0.15014839,  0.09695113,  0.7559396 ,  0.8479074 ,\n",
       "        0.27288342,  0.5657095 ,  0.78672016,  0.15305841,  0.03947842,\n",
       "        0.32497597,  0.08505332,  1.0847458 ,  0.56631404,  0.15003562,\n",
       "        0.5820644 ,  0.53416806,  0.22781897,  0.6643868 ,  0.78666097,\n",
       "        0.16973561,  0.3059578 ,  0.02693033,  0.4774053 ,  0.16975802,\n",
       "        0.09509552,  0.8706163 ,  0.66381514,  0.57367074,  0.311059  ,\n",
       "        0.66730106,  0.3656193 ,  0.10291672,  0.6898089 ,  0.05892444,\n",
       "        0.3186897 , -0.17201126, -0.01247799,  0.5736706 ,  0.26039726,\n",
       "        0.44160366,  0.8924959 ,  0.5665213 ,  0.3955896 ,  0.25655144,\n",
       "        0.17629886,  0.15980297,  0.33872586,  0.05900705,  0.18288535,\n",
       "        0.09509552,  1.0040249 ,  0.55306983,  0.10461986,  0.72541356,\n",
       "        0.8575932 ,  0.33200407,  0.6370972 ,  0.1502009 ,  0.15665996,\n",
       "        0.5343226 ,  0.647128  ,  0.92080534,  0.6609721 ,  0.07869852,\n",
       "       -0.03212297,  0.72703075, -0.2002815 ,  0.05696452,  0.14393216,\n",
       "        0.7919055 ,  0.6988803 ,  0.90795577,  0.6779653 ,  0.3557154 ,\n",
       "        0.5756069 ,  0.1996991 ,  0.77825946,  0.88867295,  1.0377625 ,\n",
       "        0.1304596 ,  0.16807228,  0.04580915,  0.14889467,  1.0262773 ,\n",
       "        0.31992954,  0.13714594,  0.58466303,  0.27991152,  0.37706292,\n",
       "        0.4124248 ,  0.09045589,  0.87285465,  0.14459068,  0.5538573 ,\n",
       "        0.8391688 ,  0.22219217,  0.78762877,  0.15666085,  0.02066958,\n",
       "        0.828389  ,  0.4525274 ,  0.08504474,  0.03449559,  0.8370538 ,\n",
       "        0.06832373,  0.96033525,  0.31898093,  0.08616507,  0.3458259 ,\n",
       "        0.15039724,  0.72962284,  0.02629006,  0.13712525,  0.2603768 ,\n",
       "        0.16359514,  0.90998995,  0.0850594 ,  0.52414095,  0.14364892,\n",
       "        0.67702687,  0.15654719,  0.04614246,  0.39530104,  0.2603768 ,\n",
       "        0.15667206,  0.06581557,  0.29021156], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.63523674e-01,  4.37890291e-02,  1.28666997e-01,  2.79394984e-01,\n",
       "        2.53348708e-01,  3.64251971e-01,  2.86423087e-01,  2.70698667e-01,\n",
       "        9.76909399e-02,  1.01459289e+00,  6.64512396e-01,  2.92418122e-01,\n",
       "        4.36051369e-01,  4.96546626e-01,  6.47502065e-01,  2.48610020e-01,\n",
       "        3.56945276e-01,  1.56791687e-01,  1.03409791e+00,  7.52273440e-01,\n",
       "        2.88993955e-01,  9.27888989e-01,  2.30505168e-01,  1.08474576e+00,\n",
       "        3.01096678e-01,  6.63820326e-01,  1.32372618e-01,  9.90225077e-02,\n",
       "        1.98662281e-02,  1.01690078e+00,  1.29002869e-01,  3.60463500e-01,\n",
       "        1.16662443e-01,  1.04312015e+00,  9.45922971e-01,  1.96682334e-01,\n",
       "        8.38119209e-01,  1.11091018e-01,  5.68270862e-01,  6.87629938e-01,\n",
       "        4.18936372e-01,  1.44589782e-01,  1.05941761e+00,  1.89213514e-01,\n",
       "       -1.88457370e-01,  1.02704406e+00,  3.25467527e-01,  5.97389936e-02,\n",
       "        2.60929346e-01,  7.75638819e-01,  6.48006797e-01,  1.51649356e-01,\n",
       "        1.50091588e-01,  3.32576036e-02,  1.16377294e-01,  3.18980932e-01,\n",
       "        9.01537538e-01,  6.30368948e-01, -2.28065252e-02,  3.51435244e-01,\n",
       "        1.76185191e-01,  8.84233177e-01,  9.42484021e-01,  5.32041788e-02,\n",
       "        6.89866602e-01,  4.70956564e-02,  6.18807435e-01,  1.11078978e-01,\n",
       "        3.14541876e-01,  4.29860592e-01,  8.13122511e-01,  1.51239991e-01,\n",
       "        5.01515090e-01,  3.69976401e-01,  1.42267764e-01,  1.27314210e-01,\n",
       "        4.28309441e-02,  1.56712472e-01,  2.53509223e-01,  1.24009609e-01,\n",
       "        1.86915874e-01,  3.35768163e-01,  7.35551953e-01,  1.24121070e-01,\n",
       "        7.83820450e-01,  6.31293535e-01,  3.72065902e-01,  4.90608931e-01,\n",
       "        3.34076583e-01,  8.17900419e-01,  7.20621347e-02,  7.52421796e-01,\n",
       "        4.68762398e-01,  2.60935485e-01,  3.68287385e-01,  1.58375859e-01,\n",
       "        1.96683228e-01,  1.30583584e-01,  1.04916096e-01,  2.62855053e-01,\n",
       "        1.43657506e-01,  9.69511271e-02, -3.35754156e-02,  7.31878281e-02,\n",
       "        1.29539907e-01,  3.78841341e-01,  7.52988219e-01,  1.76247180e-01,\n",
       "        2.75848687e-01,  3.58050346e-01,  1.63017452e-01,  5.73115110e-01,\n",
       "        1.25193715e-01,  8.30412269e-01,  6.10658288e-01,  8.06094408e-01,\n",
       "        7.31884480e-01, -1.48150921e-02,  5.19900978e-01,  1.17769659e-01,\n",
       "        6.05403900e-01,  2.28371501e-01,  3.57528210e-01,  4.74951148e-01,\n",
       "        3.32004070e-01,  4.67877209e-01,  7.84926713e-01,  1.89569950e-01,\n",
       "        9.83043730e-01,  5.05904019e-01,  8.07867229e-01,  8.99283528e-01,\n",
       "        3.07214141e-01,  4.37411904e-01,  7.94740915e-02,  7.88732767e-02,\n",
       "        9.79430676e-02,  9.87521172e-01,  9.10439968e-01,  8.52402151e-01,\n",
       "        1.34164870e-01, -6.79366589e-02,  6.44285679e-01,  1.15947604e-01,\n",
       "        2.18584299e-01,  4.57643509e-01,  1.43271983e-01,  6.99602425e-01,\n",
       "        2.66738653e-01,  5.42951107e-01, -9.08924341e-02,  7.21960545e-01,\n",
       "        5.49925923e-01, -2.21425295e-02,  3.71128976e-01,  4.82304454e-01,\n",
       "        1.04182303e+00,  6.94644451e-03,  6.65583551e-01,  1.62413538e-01,\n",
       "        2.08284259e-01,  1.15125000e-01,  1.56712472e-01,  9.92487729e-01,\n",
       "        2.06805825e-01,  8.39168787e-01,  3.79078746e-01,  6.05835915e-01,\n",
       "        5.40988803e-01,  9.77392733e-01,  1.35621667e-01,  7.60326266e-01,\n",
       "        9.81084108e-02,  9.10084963e-01,  1.71502948e-01,  1.09374034e+00,\n",
       "        2.86423087e-01, -9.78338718e-03,  1.24154627e-01,  1.30634367e-01,\n",
       "        1.89511418e-01, -1.23919249e-02,  2.81167865e-01,  6.41223788e-01,\n",
       "        1.69703782e-01,  4.34756279e-04,  6.53439760e-02,  7.02238739e-01,\n",
       "        5.90048373e-01,  9.14092124e-01,  1.89270318e-01,  2.86665082e-01,\n",
       "        6.29320025e-01,  6.12864554e-01,  2.67461538e-02,  6.90293610e-01,\n",
       "        1.56686664e-01,  7.20822692e-01,  7.90848732e-02,  2.09041715e-01,\n",
       "        8.84497166e-02,  3.05957794e-01,  1.69214964e-01,  7.75929689e-02,\n",
       "        2.13115036e-01,  1.63350642e-01,  8.61721158e-01,  5.13305068e-01,\n",
       "        1.56686664e-01,  1.56655669e-01,  1.33921981e-01,  4.14593697e-01,\n",
       "        7.85168409e-02,  4.42499876e-01,  8.89833331e-01,  4.42636788e-01,\n",
       "        7.61029959e-01,  6.11911178e-01,  1.69678807e-01,  1.12170577e-01,\n",
       "        2.95283556e-01,  2.55007982e-01,  7.85418749e-02,  9.18324292e-01,\n",
       "        2.68144727e-01,  7.75638819e-01,  5.30385971e-02,  4.93820906e-02,\n",
       "        1.00363135e-01,  3.58741403e-01,  2.00961828e-02,  8.45253944e-01,\n",
       "        4.02761519e-01,  1.09539151e-01,  1.31274462e-02,  2.68144727e-01,\n",
       "        2.99446225e-01,  8.69953871e-01,  4.11653519e-01,  3.82668614e-01,\n",
       "        6.24051094e-02,  3.32004070e-01,  1.66420579e-01,  1.34578943e-02,\n",
       "        1.10150933e-01,  6.90988421e-01,  1.60629690e-01,  7.33934104e-01,\n",
       "        7.82150388e-01,  9.29460883e-01,  4.23091650e-02,  1.08760929e+00,\n",
       "        1.82567656e-01,  8.53694797e-01,  2.48391688e-01,  9.18189108e-01,\n",
       "        7.14039683e-01,  1.30500913e-01,  4.91387367e-01,  6.37930036e-01,\n",
       "        2.06047297e-02, -5.33009768e-02,  6.24662697e-01,  1.38471484e-01,\n",
       "        7.57812262e-01,  2.61393547e-01,  5.40872157e-01,  1.11431122e-01,\n",
       "        9.19820845e-01,  2.09869981e-01,  6.23770475e-01,  2.87114143e-01,\n",
       "        3.04455936e-01,  7.74053097e-01,  6.02279782e-01,  1.00930715e+00,\n",
       "        1.00597692e+00,  6.63711846e-01,  2.09706366e-01,  3.87579918e-01,\n",
       "        1.73025191e-01,  6.95713341e-01,  1.30459607e-01,  1.01202250e+00,\n",
       "        7.93158114e-01,  6.70306087e-01,  8.75935733e-01,  2.68388689e-01,\n",
       "       -8.34642649e-02,  8.09024036e-01,  5.32007098e-01,  8.92771959e-01,\n",
       "        2.46837139e-01,  1.10485089e+00,  3.15813184e-01,  1.09231389e+00,\n",
       "        3.41028929e-01,  1.21141732e-01,  1.76190376e-01,  3.54722679e-01,\n",
       "        6.46484375e-01,  7.20481992e-01,  3.59306693e-01,  6.37805104e-01,\n",
       "        1.49393082e-01,  1.43168688e-01,  8.19117546e-01,  2.86423087e-01,\n",
       "        7.75364637e-02,  2.47353673e-01,  1.05334735e+00,  7.41713881e-01,\n",
       "        1.54358029e-01,  1.63224041e-01,  2.57867098e-01,  7.30057836e-01,\n",
       "        8.68232727e-01,  9.35737193e-01,  4.36605215e-02,  6.14570141e-01,\n",
       "        4.58299935e-01,  3.75781476e-01, -3.88402939e-02,  1.37063265e-01,\n",
       "        2.88008809e-01,  1.11099601e-01,  4.96865749e-01, -2.72747278e-02,\n",
       "        3.89078021e-01,  1.30352139e-01,  4.85673845e-01,  3.39771986e-01,\n",
       "        3.08643997e-01,  5.14901876e-02,  8.74412775e-01,  1.17420971e-01,\n",
       "        1.50469542e-01,  6.92057610e-03,  5.39267719e-01,  3.80271256e-01,\n",
       "        1.82885349e-01,  8.50594044e-02,  7.41713881e-01,  3.80690694e-01,\n",
       "        1.17590547e-01,  6.37790442e-01,  7.07541704e-02,  4.03874516e-01,\n",
       "        9.07058537e-01,  1.02031314e+00,  1.76194668e-01,  2.76092350e-01,\n",
       "        3.71076882e-01,  6.43608749e-01,  4.86902356e-01,  3.39801669e-01,\n",
       "        5.23414731e-01,  7.73536563e-01, -4.23412323e-02,  3.41493785e-01,\n",
       "        1.32831693e-01,  6.55504465e-02,  6.69351459e-01,  7.34983683e-01,\n",
       "        2.42427826e-01,  1.63466871e-01,  1.11431122e-01,  1.08031452e+00,\n",
       "       -1.04124665e-01,  9.95656610e-01,  8.66343081e-01,  8.13050210e-01,\n",
       "        1.06253123e+00,  3.67361903e-01,  2.54439116e-02,  3.25492501e-01,\n",
       "        1.08386147e+00,  2.99549580e-01,  7.69194543e-01,  5.35399795e-01,\n",
       "        6.69351459e-01,  4.01710033e-01,  1.70173824e-01,  9.37085450e-01,\n",
       "        9.51299012e-01,  5.79903603e-01,  4.58293021e-01,  1.56839073e-01,\n",
       "        5.72873294e-01,  2.70676851e-01, -3.95838022e-02,  3.57533813e-01,\n",
       "        8.79308343e-01,  3.08969975e-01,  8.32805037e-01,  5.42287171e-01,\n",
       "        4.37391222e-01,  5.97798884e-01,  1.89889669e-02,  5.14024377e-01,\n",
       "        1.10466027e+00,  1.69652998e-01,  1.36971176e-01,  8.50852728e-02,\n",
       "        3.20121050e-02,  1.04919553e-01,  7.61029959e-01, -1.91402435e-02,\n",
       "        5.73266029e-01,  7.93867648e-01,  7.87076235e-01,  9.09265876e-01,\n",
       "        6.60731792e-01,  6.64246500e-01,  8.13122511e-01,  1.63198233e-01,\n",
       "        8.40754449e-01, -2.46942043e-03,  4.08460617e-01,  1.00257838e+00,\n",
       "       -1.34779215e-02,  1.50169075e-01,  5.67283571e-01,  7.68963575e-01,\n",
       "        3.97220552e-01, -1.65305257e-01,  3.75988483e-01,  6.21662378e-01,\n",
       "        8.65270495e-01,  3.01689625e-01,  2.85906553e-01,  6.24775887e-01,\n",
       "        1.37177765e-01,  1.82885349e-01,  8.00099373e-01,  3.64251971e-01,\n",
       "        3.64561915e-01,  1.06668544e+00,  5.28036118e-01,  1.98868513e-02,\n",
       "        5.21299481e-01,  5.47585905e-01,  7.48006821e-01,  4.50468600e-01,\n",
       "        4.58311856e-01,  7.64490783e-01,  1.84924185e-01,  6.12698913e-01,\n",
       "        1.77147627e-01,  7.23775029e-01,  3.57533813e-01,  1.00023103e+00,\n",
       "        1.17611229e-01,  3.78714085e-01,  7.02529192e-01,  5.73755503e-02,\n",
       "        1.39963329e-01,  3.31487536e-01,  1.63183630e-01,  4.59839106e-02,\n",
       "        4.28704023e-02,  1.89270318e-01,  3.98321807e-01,  9.15709734e-02,\n",
       "        3.29607725e-02,  2.55679727e-01,  5.27924299e-02,  1.53397441e-01,\n",
       "        1.50009811e-01,  9.03993189e-01, -1.27536058e-02,  1.04747498e+00,\n",
       "        1.69735610e-01,  7.20621347e-02,  4.52246428e-01, -3.86965275e-02,\n",
       "        6.57262266e-01,  6.60728335e-01,  1.24122798e-01,  2.08284259e-01,\n",
       "        5.50276220e-01,  7.32559681e-01,  9.91734266e-02,  1.25352144e-01,\n",
       "        1.63183630e-01,  7.75488138e-01,  1.92202628e-01,  2.28371501e-01,\n",
       "        9.94931340e-01,  1.31959915e-01,  2.74392068e-01,  2.29404688e-01,\n",
       "        3.13394725e-01,  3.78841341e-01,  6.28173947e-01,  1.24122798e-01,\n",
       "        1.24097824e-01,  1.76139712e-01,  5.03417492e-01,  9.81084108e-02,\n",
       "        6.51019335e-01,  1.50035620e-01,  7.17409849e-02,  1.08065546e+00,\n",
       "        8.66715312e-01,  1.64288998e-01,  8.50594044e-02,  7.55108178e-01,\n",
       "        1.14494205e-01,  5.60392141e-01,  1.04583859e-01,  6.53594732e-02,\n",
       "        1.03488481e+00,  2.93979764e-01,  3.18980932e-01,  2.28969693e-01,\n",
       "       -3.86345387e-02,  6.61133528e-02,  9.80764627e-02,  5.10959804e-01,\n",
       "        6.49713099e-01,  1.77518725e-01,  1.06811202e+00,  2.60376811e-01,\n",
       "        5.90983987e-01,  9.84079838e-02,  9.29233611e-01,  4.05913234e-01,\n",
       "        3.70090902e-01,  1.56191826e-01,  1.01579070e-01,  4.83739316e-01,\n",
       "        1.69703782e-01,  4.92886662e-01, -2.07825065e-01,  5.14049053e-01,\n",
       "        3.30907047e-01,  3.77068520e-01,  6.94644451e-03,  1.49582088e-01,\n",
       "        9.30548489e-01,  4.93784189e-01,  1.05182767e-01,  4.58970547e-01,\n",
       "        1.11099601e-01,  1.04563117e-01,  2.12788582e-04,  8.51498842e-02,\n",
       "        5.30779362e-03,  9.48525667e-02,  5.19969761e-01,  1.12285042e+00,\n",
       "        6.58279717e-01,  3.94784212e-02,  7.00777411e-01,  7.79654324e-01,\n",
       "        1.50200903e-01,  6.57339752e-01,  6.55504465e-02,  7.07029104e-01,\n",
       "        1.08814549e+00,  4.01873708e-01,  1.69703782e-01,  8.71384144e-03,\n",
       "        8.08196664e-01,  1.14122450e-01,  7.44411111e-01,  9.31195021e-01,\n",
       "        4.43902791e-01], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train = regressor.predict(X_train)\n",
    "y_pred_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = y_pred_train >= 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = y_pred_test >= 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[294,  43],\n",
       "       [ 67, 165]], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_train , y_pred_train)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8066783831282952"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "459/569\n",
    "##ACCURACY ON TRAINING SET -- 81%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[69, 18],\n",
       "       [19, 37]], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test , y_pred_test)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7342657342657343"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "105/143\n",
    "##ACCURACY ON TEST SET -- 74%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "##CLASSIFICATION USING TENSOR FLOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(features, labels, training=True, batch_size=256):\n",
    "    \n",
    "    #Convert the inputs to a dataset\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "    \n",
    "    #Shuffle and repeat if you are in training mode\n",
    "    if training:\n",
    "        dataset  = dataset.shuffle(1000).repeat()\n",
    "        \n",
    "    return dataset.batch(batch_size)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_column = tf.feature_column.categorical_column_with_vocabulary_list(key=\"Sex\", vocabulary_list=[\"male\", \"female\"], default_value=0)\n",
    "feature_col = [\n",
    "    tf.feature_column.numeric_column(key='Pclass'),\n",
    "    tf.feature_column.indicator_column(categorical_column),\n",
    "    tf.feature_column.numeric_column(key='Age')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-59c860b2ca7c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mfeature_col\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mCAT_COL\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mvocab\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#list of all unique values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mfeature_col\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_column\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategorical_column_with_vocabulary_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "#feature columns describe how to use the input\n",
    "CAT_COL = [\"Sex\", \"Embarked\", \"Pclass\"]\n",
    "NUM_COL = [\"Age\", \"Fare\",\"Parch\",\"SibSp\"]\n",
    "#print(X[\"Age\"].unique())\n",
    "feature_col = []\n",
    "for col in CAT_COL :\n",
    "    vocab = X_train[col].unique()  #list of all unique values\n",
    "    feature_col.append(tf.feature_column.categorical_column_with_vocabulary_list(col, vocab))\n",
    "    \n",
    "for col in NUM_COL:\n",
    "    feature_col.append(tf.feature_column.numeric_column(col, dtype= tf.float32))\n",
    " \n",
    "print(feature_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\91930\\AppData\\Local\\Temp\\tmpi3q8xg0o\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\91930\\\\AppData\\\\Local\\\\Temp\\\\tmpi3q8xg0o', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Build DNN with 2 hidden layers with 30 and 10 hidden nodes each\n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns = feature_col,\n",
    "    # 2 hidden layers with 30 and 10 nodes respectively\n",
    "    hidden_units = [30,10],\n",
    "    #model must choose between 1 classes \n",
    "    n_classes=2\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\91930\\AppData\\Local\\Temp\\tmpi3q8xg0o\\model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 0.628003, step = 0\n",
      "INFO:tensorflow:global_step/sec: 129.571\n",
      "INFO:tensorflow:loss = 0.614547, step = 100 (0.773 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.047\n",
      "INFO:tensorflow:loss = 0.597836, step = 200 (0.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.148\n",
      "INFO:tensorflow:loss = 0.6007322, step = 300 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.091\n",
      "INFO:tensorflow:loss = 0.59338486, step = 400 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 281.145\n",
      "INFO:tensorflow:loss = 0.6224104, step = 500 (0.355 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.335\n",
      "INFO:tensorflow:loss = 0.5821426, step = 600 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 281.719\n",
      "INFO:tensorflow:loss = 0.5825814, step = 700 (0.355 sec)\n",
      "INFO:tensorflow:global_step/sec: 278.202\n",
      "INFO:tensorflow:loss = 0.58568627, step = 800 (0.360 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.23\n",
      "INFO:tensorflow:loss = 0.5726654, step = 900 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 291.815\n",
      "INFO:tensorflow:loss = 0.571279, step = 1000 (0.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.397\n",
      "INFO:tensorflow:loss = 0.57343566, step = 1100 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 291.502\n",
      "INFO:tensorflow:loss = 0.5751009, step = 1200 (0.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.743\n",
      "INFO:tensorflow:loss = 0.57756114, step = 1300 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.133\n",
      "INFO:tensorflow:loss = 0.56043303, step = 1400 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 283.759\n",
      "INFO:tensorflow:loss = 0.5436412, step = 1500 (0.352 sec)\n",
      "INFO:tensorflow:global_step/sec: 281.765\n",
      "INFO:tensorflow:loss = 0.56520295, step = 1600 (0.355 sec)\n",
      "INFO:tensorflow:global_step/sec: 278.007\n",
      "INFO:tensorflow:loss = 0.5727241, step = 1700 (0.360 sec)\n",
      "INFO:tensorflow:global_step/sec: 361.671\n",
      "INFO:tensorflow:loss = 0.54500985, step = 1800 (0.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.913\n",
      "INFO:tensorflow:loss = 0.532443, step = 1900 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.098\n",
      "INFO:tensorflow:loss = 0.548981, step = 2000 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.484\n",
      "INFO:tensorflow:loss = 0.5358321, step = 2100 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.33\n",
      "INFO:tensorflow:loss = 0.55728245, step = 2200 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.541\n",
      "INFO:tensorflow:loss = 0.5522658, step = 2300 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.396\n",
      "INFO:tensorflow:loss = 0.5386306, step = 2400 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.348\n",
      "INFO:tensorflow:loss = 0.548815, step = 2500 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.848\n",
      "INFO:tensorflow:loss = 0.56786853, step = 2600 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.705\n",
      "INFO:tensorflow:loss = 0.5576004, step = 2700 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.486\n",
      "INFO:tensorflow:loss = 0.5457254, step = 2800 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.417\n",
      "INFO:tensorflow:loss = 0.51075315, step = 2900 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.827\n",
      "INFO:tensorflow:loss = 0.5152521, step = 3000 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.942\n",
      "INFO:tensorflow:loss = 0.55408573, step = 3100 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.075\n",
      "INFO:tensorflow:loss = 0.5310329, step = 3200 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.405\n",
      "INFO:tensorflow:loss = 0.53218436, step = 3300 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.473\n",
      "INFO:tensorflow:loss = 0.5380601, step = 3400 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.784\n",
      "INFO:tensorflow:loss = 0.5271653, step = 3500 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.627\n",
      "INFO:tensorflow:loss = 0.52909833, step = 3600 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.396\n",
      "INFO:tensorflow:loss = 0.54899126, step = 3700 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.859\n",
      "INFO:tensorflow:loss = 0.5193684, step = 3800 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 282.505\n",
      "INFO:tensorflow:loss = 0.4942417, step = 3900 (0.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.752\n",
      "INFO:tensorflow:loss = 0.51241434, step = 4000 (0.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.863\n",
      "INFO:tensorflow:loss = 0.5216771, step = 4100 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 283.867\n",
      "INFO:tensorflow:loss = 0.5040387, step = 4200 (0.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.745\n",
      "INFO:tensorflow:loss = 0.5154177, step = 4300 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.892\n",
      "INFO:tensorflow:loss = 0.5009296, step = 4400 (0.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.907\n",
      "INFO:tensorflow:loss = 0.54607236, step = 4500 (0.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 293.398\n",
      "INFO:tensorflow:loss = 0.5043021, step = 4600 (0.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 256.956\n",
      "INFO:tensorflow:loss = 0.5253106, step = 4700 (0.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 293.536\n",
      "INFO:tensorflow:loss = 0.5063456, step = 4800 (0.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 279.275\n",
      "INFO:tensorflow:loss = 0.5114236, step = 4900 (0.360 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5000...\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into C:\\Users\\91930\\AppData\\Local\\Temp\\tmpi3q8xg0o\\model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5000...\n",
      "INFO:tensorflow:Loss for final step: 0.49316406.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x1898c19d088>"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.train(\n",
    "    input_fn= lambda: input_fn(X_train, y_train, training=True),\n",
    "    steps=5000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-07-23T18:24:40Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\91930\\AppData\\Local\\Temp\\tmpi3q8xg0o\\model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 3.12427s\n",
      "INFO:tensorflow:Finished evaluation at 2020-07-23-18:24:43\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.7902098, accuracy_baseline = 0.6083916, auc = 0.8207102, auc_precision_recall = 0.79467404, average_loss = 0.52414584, global_step = 5000, label/mean = 0.3916084, loss = 0.52414584, precision = 0.84210527, prediction/mean = 0.37534118, recall = 0.5714286\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: C:\\Users\\91930\\AppData\\Local\\Temp\\tmpi3q8xg0o\\model.ckpt-5000\n",
      "\n",
      "test set 0.790\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_result = classifier.evaluate(\n",
    "    input_fn = lambda: input_fn(X_test, y_test, training= False)\n",
    ")\n",
    "print(\"\\ntest set {accuracy:0.3f}\\n\".format(**test_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\91930\\AppData\\Local\\Temp\\tmpi3q8xg0o\\model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Sex          female\n",
      "Age              38\n",
      "SibSp             1\n",
      "Parch             0\n",
      "Pclass            1\n",
      "Embarked          C\n",
      "Fare        71.2833\n",
      "Name: 1, dtype: object\n",
      "1\n",
      "0.4461922\n"
     ]
    }
   ],
   "source": [
    "result = list(classifier.predict(test_input_fn))\n",
    "print(X_test.loc[1])\n",
    "print(y_test.loc[1])\n",
    "print(result[1][\"probabilities\"][1])\n",
    "res = []\n",
    "for i in range(len(result)):\n",
    "    if result[i][\"probabilities\"][1]>=0.5:\n",
    "        res.append(1)\n",
    "    else:\n",
    "        res.append(0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[81, 24],\n",
       "       [ 6, 32]], dtype=int64)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(res , y_test)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7902097902097902"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "113/143\n",
    "##ACCURACY ON TEST SET-- 80%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##SKLEARN LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91930\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=0, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Logistic Regression to the Training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = classifier.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(571,)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[286,  50],\n",
       "       [ 65, 170]], dtype=int64)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_train , y_pred_train)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8014059753954306"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "456/569\n",
    "#ACCURACY ON TRAINING SET -- 82%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[71, 16],\n",
       "       [18, 38]], dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test , y_pred_test)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7622377622377622"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "109/143\n",
    "#ACCURACY ON TEST SET -- 77%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "##SKLEARN KERNEL SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91930\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=0,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Kernel SVM to the Training set\n",
    "from sklearn.svm import SVC\n",
    "classifier_svc = SVC(kernel = 'rbf', random_state = 0)\n",
    "classifier_svc.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[323,  29],\n",
       "       [ 13, 206]], dtype=int64)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the Train set results\n",
    "y_pred_train = classifier_svc.predict(X_train)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_pred_train, y_train)\n",
    "cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9264448336252189"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "529/571\n",
    "#ACCURACY ON TRAINING SET -- 92%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[61, 21],\n",
       "       [27, 34]], dtype=int64)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred_test = classifier_svc.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_pred_test, y_test)\n",
    "cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7342657342657343"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "105/143\n",
    "#ACCURACY ON TEST SET -- 74%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"titanic.csv\")\n",
    "dataset.shape\n",
    "dataset.dropna(axis=0, inplace=True, subset=[\"Sex\", \"Age\", \"Pclass\",\"Fare\"])\n",
    "#print(dataset)\n",
    "y = dataset[\"Survived\"]\n",
    "X = dataset.iloc[:, 4:8]\n",
    "X=np.column_stack((X, dataset[\"Pclass\"]))\n",
    "X= np.column_stack((X,dataset[\"Embarked\"]))\n",
    "X=np.column_stack((X, dataset[\"Fare\"]))\n",
    "X = pd.DataFrame(data=dataset, columns=[\"Sex\", \"Age\", \"Pclass\",\"Fare\"])\n",
    "#X.dropna(axis=0, inplace=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "429    1\n",
       "14     0\n",
       "592    0\n",
       "751    1\n",
       "286    1\n",
       "      ..\n",
       "75     0\n",
       "801    1\n",
       "623    0\n",
       "16     0\n",
       "119    0\n",
       "Name: Survived, Length: 143, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.20, random_state=32)\n",
    "X_train.shape\n",
    "X_test.shape\n",
    "y_train\n",
    "y_test\n",
    "\n",
    "#X_train.dropna(subset=[\"Pclass\"])\n",
    "#X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "##SKLEARN RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier_rf = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "classifier_rf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = classifier_rf.predict(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(143,)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test = classifier_rf.predict(X_test)\n",
    "y_pred_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[74, 16],\n",
       "       [14, 39]], dtype=int64)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred_test = classifier.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_pred_test, y_test)\n",
    "cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7902097902097902"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "113/143\n",
    "#ACCURACY ON TEST SET--80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[332,  15],\n",
       "       [  4, 220]], dtype=int64)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the Train set results\n",
    "y_pred_test = classifier_rf.predict(X_train)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_pred_train, y_train)\n",
    "cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9667250437828371"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "552/571\n",
    "#ACCURACY ON TRAIN SET-- 97%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = classifier_rf.predict([[1.0,0.0, 8, 2, 250.25]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rf_titanic.pkl']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(classifier_rf, \"rf_titanic.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['svc_titanic.pkl']"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(classifier_svc, \"svc_titanic.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
